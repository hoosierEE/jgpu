#+PROPERTY: header-args:J :results output :exports both
#+SETUPFILE: ~/org/informal-paper.org
#+TITLE: Project Proposal
#+SUBTITLE: Course: ENGR-E 517. Professor: Thomas Sterling.
#+AUTHOR: Alex Shroyer
#+DATE: 2021-10-03

#+begin_export latex
\section*{ABSTRACT}
#+end_export
Adding GPU support to the an interpreted programming language is novel, useful, and improves performance.

The J programming language[fn:0] is a high-level, array-oriented, free and open source[fn:1] interpreted language.
Originally designed by Kenneth Iverson as a successor to APL, it shares much of APL's expressivity and performance characteristics.
Unlike APL, J uses an ASCII character set.
While the J interpreter is well-optimized for modern CPUs (especially those with SIMD and vector extensions), support for multi-core/GPU is limited.
Using /matrix product/ as a demonstration, this project will show the benefits of integrating GPU acceleration with a modern programming language.

[fn:0] https://www.jsoftware.com/
[fn:1] https://github.com/jsoftware/jsource

* Experiments
- Experiment A :: generates matrixes on the CPU, executes the matrix multiplication on the GPU, and transfers the answer back to the CPU.
- Experiment B :: generates the data on the GPU instead; subsequent steps identical to (A).

The following performance metrics will be recorded:
1. time for (A) for matrixes of various sizes
2. total time for (B) for matrixes of various sizes
3. measure performance of matmul for various matrix sizes on GPU
4. determine break-even data size (if any) where GPU is faster

